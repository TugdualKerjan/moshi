{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tugdual/miniconda3/envs/speechtok/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_81686/1474467755.py:47: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  key: jax.numpy.array(numpy.array(value.detach()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rvq_first.input_proj.weight', 'rvq_first.output_proj.weight', 'rvq_rest.input_proj.weight', 'rvq_rest.output_proj.weight'])\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import torch\n",
    "import numpy\n",
    "from huggingface_hub import hf_hub_download\n",
    "import jax\n",
    "\n",
    "from moshi.moshi.models.loaders import get_mimi\n",
    "from moshi_jax.moshi_jax.quantization.vq import (\n",
    "    SplitResidualVectorQuantizer as JAXQuantizer,\n",
    ")\n",
    "\n",
    "_seanet_kwargs = {\n",
    "    \"channels\": 1,\n",
    "    \"dimension\": 512,\n",
    "    \"causal\": True,\n",
    "    \"n_filters\": 64,\n",
    "    \"n_residual_layers\": 1,\n",
    "    \"activation\": \"ELU\",\n",
    "    \"compress\": 2,\n",
    "    \"dilation_base\": 2,\n",
    "    \"disable_norm_outer_blocks\": 0,\n",
    "    \"kernel_size\": 7,\n",
    "    \"residual_kernel_size\": 3,\n",
    "    \"last_kernel_size\": 3,\n",
    "    # We train using weight_norm but then the weights are pre-processed for inference so\n",
    "    # that we can use a normal convolution.\n",
    "    \"norm\": \"none\",\n",
    "    \"pad_mode\": \"constant\",\n",
    "    \"ratios\": [8, 6, 5, 4],\n",
    "    \"true_skip\": True,\n",
    "}\n",
    "_quantizer_kwargs = {\n",
    "    \"dimension\": 256,\n",
    "    \"n_q\": 8,\n",
    "    \"bins\": 2048,\n",
    "    \"input_dimension\": _seanet_kwargs[\"dimension\"],\n",
    "    \"output_dimension\": _seanet_kwargs[\"dimension\"],\n",
    "}\n",
    "\n",
    "device = torch.get_default_device()\n",
    "mimi_weight = hf_hub_download(\n",
    "    \"kyutai/moshiko-pytorch-bf16\", \"tokenizer-e351c8d8-checkpoint125.safetensors\"\n",
    ")\n",
    "model = get_mimi(mimi_weight)\n",
    "jax_quantizer = JAXQuantizer(**_quantizer_kwargs, key=jax.random.key(1))\n",
    "\n",
    "their_params = {\n",
    "    key: jax.numpy.array(numpy.array(value.detach()))\n",
    "    for key, value in model.quantizer.named_parameters()\n",
    "}\n",
    "print(their_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rvq_first.input_proj.weight\n",
      "rvq_first.output_proj.weight\n",
      "rvq_first.vq.layers[0]._codebook.embedding_sum\n",
      "rvq_first.vq.layers[0]._codebook.embedding\n",
      "rvq_rest.input_proj.weight\n",
      "rvq_rest.output_proj.weight\n",
      "rvq_rest.vq.layers[0]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[0]._codebook.embedding\n",
      "rvq_rest.vq.layers[1]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[1]._codebook.embedding\n",
      "rvq_rest.vq.layers[2]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[2]._codebook.embedding\n",
      "rvq_rest.vq.layers[3]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[3]._codebook.embedding\n",
      "rvq_rest.vq.layers[4]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[4]._codebook.embedding\n",
      "rvq_rest.vq.layers[5]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[5]._codebook.embedding\n",
      "rvq_rest.vq.layers[6]._codebook.embedding_sum\n",
      "rvq_rest.vq.layers[6]._codebook.embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81686/116529712.py:21: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  numpy.array(model.quantizer.rvq_rest.vq.layers[idx]._codebook.embedding)\n",
      "/tmp/ipykernel_81686/116529712.py:15: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  numpy.array(model.quantizer.rvq_first.vq.layers[0]._codebook.embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T aaa tensor([[ 10.5174,   3.9937,  -7.0157,  10.9582, -12.2908,   3.1525,   3.3307,\n",
      "           2.8719,   1.2311, -11.9664],\n",
      "        [  7.1068,  -6.7943,  12.1126,   2.1296,  -0.4890,  -5.1519, -17.5122,\n",
      "          -6.2433,   9.3379,   3.9586],\n",
      "        [  7.9820,   1.6699, -10.2319,   5.7777,   1.6705,   1.2606,  -2.4887,\n",
      "         -11.0096, -10.4015,  20.2741]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T after quant: tensor([[-0.3790, -0.1061,  1.2380,  ...,  0.1567, -0.9781, -0.6167],\n",
      "        [ 0.0825,  0.3540,  0.1169,  ..., -0.2204,  0.5010,  0.6133],\n",
      "        [-0.1008,  1.1796,  0.9707,  ...,  1.1538, -0.5821,  1.2122],\n",
      "        ...,\n",
      "        [ 0.1358,  0.0322,  0.0451,  ..., -0.4313,  0.7493,  0.0605],\n",
      "        [ 0.6849, -0.6331, -1.1305,  ..., -0.0322, -0.5578,  0.2000],\n",
      "        [ 0.3323,  0.6872,  0.6157,  ...,  1.2430,  0.6165, -0.7309]])\n",
      "T aaa tensor([[-2.1185,  4.2606,  2.9183, -2.2470, -1.8193, -0.5998,  0.4217,  1.2920,\n",
      "          0.5721,  5.8613],\n",
      "        [-4.0087,  2.2728,  1.9536,  0.0080,  1.6450,  3.6164, -2.4862, -0.4034,\n",
      "         -4.9601, -0.9091],\n",
      "        [-3.8507, -1.6863, -1.4095,  3.8738,  1.4043, -5.3773,  4.6863,  1.3337,\n",
      "          2.4846, -0.0720]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T aaa tensor([[-1.8922,  4.2317,  2.6891, -2.4605, -1.7954, -0.6766,  0.7238,  1.2518,\n",
      "          0.9049,  5.6098],\n",
      "        [-3.8869,  1.5604,  1.8721, -0.6127,  1.2696,  3.7975, -2.2734, -0.5430,\n",
      "         -4.6915, -0.7864],\n",
      "        [-3.4750, -1.5624, -1.2166,  3.3439,  1.0288, -5.1818,  4.8767,  1.1435,\n",
      "          2.5767,  0.0376]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T aaa tensor([[-1.6839,  4.1350,  2.9361, -2.3580, -1.6571, -0.7253,  0.8330,  1.1253,\n",
      "          0.9788,  5.4275],\n",
      "        [-3.7426,  1.4381,  1.8573, -0.7628,  1.1845,  3.9141, -2.2731, -0.5243,\n",
      "         -4.5564, -0.7392],\n",
      "        [-3.4744, -1.4143, -0.9480,  3.2573,  0.9130, -5.2110,  4.8424,  1.1515,\n",
      "          2.4416,  0.1728]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T aaa tensor([[-1.6114,  4.1153,  3.0986, -2.3451, -1.5141, -0.7204,  0.9494,  1.2066,\n",
      "          0.9902,  5.3266],\n",
      "        [-3.6670,  1.4563,  1.9187, -0.7691,  1.1598,  3.9618, -2.3566, -0.4361,\n",
      "         -4.4369, -0.8613],\n",
      "        [-3.4190, -1.4102, -0.8629,  3.2860,  0.7402, -5.1017,  4.7436,  0.9867,\n",
      "          2.3538,  0.1154]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T aaa tensor([[-1.5535,  4.1200,  3.1748, -2.3659, -1.4653, -0.7932,  1.0703,  1.2160,\n",
      "          0.9439,  5.2931],\n",
      "        [-3.6458,  1.5418,  1.8609, -0.8019,  1.0702,  3.9476, -2.3276, -0.4877,\n",
      "         -4.3158, -0.8443],\n",
      "        [-3.4179, -1.3359, -0.7634,  3.2798,  0.7473, -5.0814,  4.6902,  1.0086,\n",
      "          2.2365,  0.1066]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T aaa tensor([[-1.6224,  4.0843,  3.1919, -2.3082, -1.4311, -0.8018,  1.1334,  1.2292,\n",
      "          0.9204,  5.2634],\n",
      "        [-3.5411,  1.5417,  1.8300, -0.8404,  1.0520,  3.8860, -2.3078, -0.4279,\n",
      "         -4.2810, -0.8711],\n",
      "        [-3.3407, -1.2762, -0.7704,  3.2433,  0.7022, -5.0883,  4.6471,  0.9810,\n",
      "          2.2237,  0.0878]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T aaa tensor([[-1.5568,  4.0607,  3.1897, -2.2969, -1.3376, -0.8007,  1.1219,  1.2340,\n",
      "          0.9861,  5.2391],\n",
      "        [-3.4499,  1.4911,  1.8071, -0.8496,  1.0899,  3.8290, -2.3057, -0.3821,\n",
      "         -4.1898, -0.9305],\n",
      "        [-3.3664, -1.2282, -0.7396,  3.2354,  0.6617, -5.1291,  4.5750,  1.0264,\n",
      "          2.1980,  0.1226]], grad_fn=<SliceBackward0>)\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T after quant: tensor([[-0.3940,  0.3818, -0.3414,  ...,  0.3952, -0.0437, -0.1187],\n",
      "        [ 0.2847, -0.1017, -0.4331,  ...,  0.0941,  0.1533,  0.1887],\n",
      "        [ 0.1830, -0.0025, -0.3703,  ...,  0.5123,  0.1199, -0.0573],\n",
      "        ...,\n",
      "        [-0.5888, -0.0593,  0.1068,  ...,  0.5668, -0.3341,  0.4139],\n",
      "        [ 0.2609,  0.5643, -0.1603,  ..., -0.1023,  0.2669, -0.2588],\n",
      "        [-0.1468, -0.2785,  0.2068,  ..., -0.1962, -0.0601, -0.2308]])\n",
      "O aaa [[ 10.515468    3.9977965  -7.017041   10.952286  -12.287186    3.1558828\n",
      "    3.328309    2.8704345   1.2309551 -11.96372  ]\n",
      " [  7.105886   -6.790003   12.112903    2.1280365  -0.4910035  -5.1534443\n",
      "  -17.5139     -6.2409863   9.339567    3.956934 ]\n",
      " [  7.982543    1.6725277 -10.23349     5.780754    1.6714315   1.2587681\n",
      "   -2.4856648 -11.00898   -10.402664   20.271336 ]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O after quant: [[-0.37898636 -0.10608578  1.237978   ...  0.15670109 -0.9781437\n",
      "  -0.6167345 ]\n",
      " [ 0.08253765  0.3539796   0.11694717 ... -0.2203536   0.50104773\n",
      "   0.6132965 ]\n",
      " [-0.10075378  1.1796284   0.9707079  ...  1.1537814  -0.5821461\n",
      "   1.2122498 ]\n",
      " ...\n",
      " [ 0.13577843  0.03219175  0.04508305 ... -0.43128777  0.7493167\n",
      "   0.06052589]\n",
      " [ 0.6849222  -0.6331043  -1.1304646  ... -0.03221679 -0.5578148\n",
      "   0.20000553]\n",
      " [ 0.33228397  0.68717057  0.61569023 ...  1.2429829   0.61646175\n",
      "  -0.7309036 ]]\n",
      "O aaa [[-2.117996    4.260871    2.918089   -2.2475538  -1.8174119  -0.5988693\n",
      "   0.42231745  1.2917295   0.5734607   5.8605366 ]\n",
      " [-4.0079584   2.2732885   1.9540484   0.0083698   1.6452402   3.616909\n",
      "  -2.4875166  -0.40458715 -4.9600687  -0.9089153 ]\n",
      " [-3.8510704  -1.6859915  -1.4095128   3.8743596   1.4036652  -5.377067\n",
      "   4.6856785   1.3337755   2.4849172  -0.07097894]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O aaa [[-1.8917084   4.232023    2.6888647  -2.460983   -1.7935361  -0.6756128\n",
      "   0.72443056  1.2515138   0.90629566  5.6090055 ]\n",
      " [-3.886178    1.5608709   1.8725145  -0.61233366  1.2699175   3.7980556\n",
      "  -2.2746942  -0.54426074 -4.6915164  -0.78620845]\n",
      " [-3.4753764  -1.5620606  -1.2166581   3.344426    1.0282555  -5.18154\n",
      "   4.876112    1.1435353   2.5770147   0.03866306]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O aaa [[-1.6834862   4.1352797   2.9359503  -2.3585446  -1.6552019  -0.72436607\n",
      "   0.83359826  1.125003    0.9801846   5.4267435 ]\n",
      " [-3.741881    1.4386334   1.8577696  -0.76247203  1.1848166   3.9146335\n",
      "  -2.2743936  -0.52550703 -4.556365   -0.7389997 ]\n",
      " [-3.4747508  -1.4139967  -0.94807327  3.2578464   0.91238594 -5.210804\n",
      "   4.8418126   1.1515214   2.44188     0.17385408]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O aaa [[-1.6109836   4.115569    3.0984573  -2.345618   -1.5122216  -0.7194034\n",
      "   0.9499653   1.2063283   0.99160784  5.325777  ]\n",
      " [-3.666293    1.4567864   1.9190997  -0.7687906   1.1600653   3.9622712\n",
      "  -2.3579185  -0.4373818  -4.4368725  -0.8611627 ]\n",
      " [-3.41931    -1.4098313  -0.8628987   3.2865283   0.73957014 -5.1015196\n",
      "   4.743018    0.98675174  2.3540487   0.1164071 ]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O aaa [[-1.5530304   4.120256    3.1746404  -2.3664005  -1.4634036  -0.7921989\n",
      "   1.0708903   1.2157282   0.9453303   5.29226   ]\n",
      " [-3.6450431   1.5422881   1.8613085  -0.80154437  1.0704681   3.9481206\n",
      "  -2.3289583  -0.4889684  -4.315818   -0.84418696]\n",
      " [-3.4182255  -1.3355736  -0.76338905  3.2803326   0.7466652  -5.0812187\n",
      "   4.689618    1.0086472   2.236782    0.10765442]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O aaa [[-1.6219751   4.084597    3.1917303  -2.3087199  -1.4292247  -0.8008779\n",
      "   1.1339698   1.2289295   0.92182547  5.26264   ]\n",
      " [-3.540397    1.5421727   1.8304893  -0.8400178   1.0522941   3.886544\n",
      "  -2.3091261  -0.4290946  -4.2809443  -0.8709027 ]\n",
      " [-3.3410692  -1.2758635  -0.77039886  3.2438095   0.7016252  -5.0880747\n",
      "   4.6464577   0.98105985  2.2239344   0.08886555]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O aaa [[-1.5563024   4.0609546   3.1895208  -2.2974093  -1.3357358  -0.7997756\n",
      "   1.1224581   1.2336988   0.98749816  5.238324  ]\n",
      " [-3.4492018   1.4916418   1.8075521  -0.8492382   1.0901936   3.829545\n",
      "  -2.3070192  -0.38337287 -4.1897492  -0.93034744]\n",
      " [-3.3667524  -1.2279092  -0.73963064  3.2359712   0.6611063  -5.128836\n",
      "   4.574396    1.0264693   2.1982512   0.12358983]]\n",
      "O shape pre input: (10, 256)\n",
      "O shape after out: (10,)\n",
      "O after quant: [[-0.3940339   0.3817656  -0.34143507 ...  0.39520156 -0.04370165\n",
      "  -0.11874962]\n",
      " [ 0.28468132 -0.10173535 -0.43307984 ...  0.09407377  0.15332425\n",
      "   0.18867803]\n",
      " [ 0.18297589 -0.00254869 -0.37029827 ...  0.51229835  0.11989999\n",
      "  -0.05727363]\n",
      " ...\n",
      " [-0.58875626 -0.05927169  0.10675049 ...  0.5668367  -0.33410525\n",
      "   0.4138717 ]\n",
      " [ 0.26092958  0.5643036  -0.16031599 ... -0.10233188  0.26688004\n",
      "  -0.25876904]\n",
      " [-0.14677846 -0.2784865   0.20675367 ... -0.19615269 -0.06008375\n",
      "  -0.23078814]]\n",
      "QuantizedResult(x=tensor([[[-9.9130e-01, -2.2863e-01,  4.3639e+00,  ...,  2.3155e+00,\n",
      "           6.7635e-01, -1.4244e+00],\n",
      "         [-8.6464e-01,  4.1772e+00, -6.1185e+00,  ...,  8.9370e-03,\n",
      "          -3.1000e-01, -1.9839e-01],\n",
      "         [-4.3718e+00, -2.0721e+00,  5.0674e+00,  ...,  4.6619e+00,\n",
      "          -5.2325e+00,  2.8459e+00],\n",
      "         ...,\n",
      "         [ 2.6599e-01,  7.7165e+00, -7.1983e-01,  ..., -5.5553e-01,\n",
      "           1.0510e-01, -8.5815e-01],\n",
      "         [ 6.2324e+00, -7.9745e-01, -3.3376e+00,  ...,  1.6640e+00,\n",
      "          -6.9443e-01, -5.4318e+00],\n",
      "         [-2.2207e+01, -1.6745e+00,  3.3729e-01,  ...,  7.8360e+00,\n",
      "          -1.0826e+01,  2.0724e+00]]], grad_fn=<AddBackward0>), codes=tensor([[[1639,  616,  897,  468,  212, 1700, 1453, 1858, 1517,  527],\n",
      "         [1367,    9, 1270,   49,  509,  649,  655, 1358,  113, 1866],\n",
      "         [  18, 1151, 1271,  377,  532, 1255,  364,  638,  174,  873],\n",
      "         [ 187, 1066,   88,  805, 1438, 1306,  415,  329, 1111, 1900],\n",
      "         [ 853,  593, 1377,  850,  934,  193, 1297,  699, 1789, 1608],\n",
      "         [1864,  316, 1079,  505, 1471, 1365, 1280, 1580, 1553, 1874],\n",
      "         [1995,  361, 2004, 1572, 1258, 1215, 1108, 1841, 1995,  319],\n",
      "         [ 117, 1392, 1894, 1152,  801, 1617,  174,  433,  371,  780]]]), bandwidth=tensor(0.8800), penalty=tensor(0.), metrics={})\n",
      "(Array([[[-9.9335790e-01, -2.2695529e-01,  4.3661594e+00, ...,\n",
      "          2.3177538e+00,  6.7420542e-01, -1.4244666e+00],\n",
      "        [-8.6586422e-01,  4.1747417e+00, -6.1181211e+00, ...,\n",
      "          1.0238413e-02, -3.0849680e-01, -1.9860275e-01],\n",
      "        [-4.3736329e+00, -2.0725951e+00,  5.0681276e+00, ...,\n",
      "          4.6608601e+00, -5.2324524e+00,  2.8441954e+00],\n",
      "        ...,\n",
      "        [ 2.6858437e-01,  7.7157631e+00, -7.1860683e-01, ...,\n",
      "         -5.5501282e-01,  1.0509145e-01, -8.5811031e-01],\n",
      "        [ 6.2329645e+00, -7.9750323e-01, -3.3382034e+00, ...,\n",
      "          1.6629505e+00, -6.9503045e-01, -5.4307895e+00],\n",
      "        [-2.2207956e+01, -1.6736190e+00,  3.3565056e-01, ...,\n",
      "          7.8340740e+00, -1.0827417e+01,  2.0722828e+00]]], dtype=float32), Array([[[1639,  616,  897,  468,  212, 1700, 1453, 1858, 1517,  527],\n",
      "        [1367,    9, 1270,   49,  509,  649,  655, 1358,  113, 1866],\n",
      "        [  18, 1151, 1271,  377,  532, 1255,  364,  638,  174,  873],\n",
      "        [ 187, 1066,   88,  805, 1438, 1306,  415,  329, 1111, 1900],\n",
      "        [ 853,  593, 1377,  850,  934,  193, 1297,  699, 1789, 1608],\n",
      "        [1864,  316, 1079,  505, 1471, 1365, 1280, 1580, 1553, 1874],\n",
      "        [1995,  361, 2004, 1572, 1258, 1215, 1108, 1841, 1995,  319],\n",
      "        [ 117, 1392, 1894, 1152,  801, 1617,  174,  433,  371,  780]]],      dtype=int32), Array([0.88], dtype=float32, weak_type=True), {})\n"
     ]
    }
   ],
   "source": [
    "import jax.tree_util as jtu\n",
    "import jax.numpy as jnp\n",
    "import numpy\n",
    "\n",
    "\n",
    "def copy_weights(path, x):\n",
    "    path = jtu.keystr(path)[1:]\n",
    "    # if \"[0].weight\"\n",
    "    if path in their_params.keys():\n",
    "        print(path)\n",
    "        return their_params[path]\n",
    "    if path == \"rvq_first.vq.layers[0]._codebook.embedding\":\n",
    "        print(path)\n",
    "        return jnp.array(\n",
    "            numpy.array(model.quantizer.rvq_first.vq.layers[0]._codebook.embedding)\n",
    "        )\n",
    "    if \".vq.layers[\" in path and \"]._codebook.embedding\" in path:\n",
    "        idx =int( path.split(\"[\")[1][0])\n",
    "        print(path)\n",
    "        return jnp.array(\n",
    "            numpy.array(model.quantizer.rvq_rest.vq.layers[idx]._codebook.embedding)\n",
    "        )\n",
    "    # print(path)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "jax_quantizer = jtu.tree_map_with_path(copy_weights, jax_quantizer)\n",
    "\n",
    "\n",
    "our_x = jax.random.normal(jax.random.key(1), shape=(1, 512, 10))\n",
    "their_x = torch.from_numpy(numpy.array(our_x))\n",
    "\n",
    "their_result = model.quantizer(their_x, 10)\n",
    "result = jax.vmap(jax_quantizer, in_axes=(0, None))(our_x, 10)\n",
    "\n",
    "print(their_result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.79974586]\n",
      " [-0.50698906]\n",
      " [-0.6074174 ]\n",
      " [ 0.05502451]\n",
      " [ 0.6204352 ]\n",
      " [ 0.47274065]\n",
      " [-0.42298052]\n",
      " [ 0.08264463]\n",
      " [ 0.14858195]\n",
      " [ 0.39576823]]\n",
      "tensor([[-0.7997],\n",
      "        [-0.5070],\n",
      "        [-0.6074],\n",
      "        [ 0.0550],\n",
      "        [ 0.6204],\n",
      "        [ 0.4727],\n",
      "        [-0.4230],\n",
      "        [ 0.0826],\n",
      "        [ 0.1486],\n",
      "        [ 0.3958]], grad_fn=<SliceBackward0>)\n",
      "[[ 10.515468     3.9977965   -7.017041    10.952286   -12.287186\n",
      "    3.1558828    3.328309     2.8704345    1.2309551  -11.96372   ]\n",
      " [  7.105886    -6.790003    12.112903     2.1280365   -0.4910035\n",
      "   -5.1534443  -17.5139      -6.2409863    9.339567     3.956934  ]\n",
      " [  7.982543     1.6725277  -10.23349      5.780754     1.6714315\n",
      "    1.2587681   -2.4856648  -11.00898    -10.402664    20.271336  ]\n",
      " [-13.358841   -12.218836     2.2199643  -10.001466    -4.9096975\n",
      "   -6.069808     6.6894493  -17.991146    11.907308    -9.91803   ]\n",
      " [  6.605486    -3.243204    -5.680114     2.2847328   -3.0460129\n",
      "    5.167364    -5.451668     4.6128893   17.174168    22.22311   ]\n",
      " [  6.3385887    1.423162    10.819897   -15.719954   -18.46531\n",
      "   10.732026     6.22188     -7.488921     3.0960534  -13.652769  ]\n",
      " [ -6.2710924   19.532923    -9.823676    17.947258    -9.207957\n",
      "    8.333099   -10.160019   -16.433773    -5.5941935   -4.361723  ]\n",
      " [  7.348508     0.98812723   8.822584     7.653268    16.55176\n",
      "   -0.9542228   14.123854     4.158411    -0.37067437   0.08568579]\n",
      " [ 16.744612    20.439737    -1.1506548   13.301779     8.622007\n",
      "   -2.9988012    7.751941     9.447334    10.195959     4.962865  ]\n",
      " [ -4.210564   -10.257925   -12.363601    13.8201885    2.3904037\n",
      "   -4.4518843    8.082906     4.9334087   -2.6226602    9.711357  ]]\n",
      "tensor([[ 10.5174,   3.9937,  -7.0157,  10.9582, -12.2908,   3.1525,   3.3307,\n",
      "           2.8719,   1.2311, -11.9664],\n",
      "        [  7.1068,  -6.7943,  12.1126,   2.1296,  -0.4890,  -5.1519, -17.5122,\n",
      "          -6.2433,   9.3379,   3.9586],\n",
      "        [  7.9820,   1.6699, -10.2319,   5.7777,   1.6705,   1.2606,  -2.4887,\n",
      "         -11.0096, -10.4015,  20.2741],\n",
      "        [-13.3588, -12.2142,   2.2271, -10.0015,  -4.9078,  -6.0700,   6.6842,\n",
      "         -17.9874,  11.9043,  -9.9225],\n",
      "        [  6.6124,  -3.2466,  -5.6770,   2.2873,  -3.0442,   5.1683,  -5.4514,\n",
      "           4.6140,  17.1686,  22.2218],\n",
      "        [  6.3335,   1.4263,  10.8140, -15.7201, -18.4680,  10.7346,   6.2212,\n",
      "          -7.4918,   3.0944, -13.6563],\n",
      "        [ -6.2742,  19.5315,  -9.8220,  17.9478,  -9.2109,   8.3344, -10.1634,\n",
      "         -16.4352,  -5.5906,  -4.3615],\n",
      "        [  7.3457,   0.9884,   8.8185,   7.6549,  16.5547,  -0.9541,  14.1197,\n",
      "           4.1562,  -0.3730,   0.0857],\n",
      "        [ 16.7460,  20.4455,  -1.1524,  13.3038,   8.6146,  -2.9973,   7.7511,\n",
      "           9.4513,  10.1938,   4.9681],\n",
      "        [ -4.2143, -10.2579, -12.3644,  13.8217,   2.3938,  -4.4548,   8.0806,\n",
      "           4.9332,  -2.6185,   9.7100]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(jax_quantizer.rvq_first.input_proj.weight[0, :10])\n",
    "print(model.quantizer.rvq_first.input_proj.weight[0, :10])\n",
    "\n",
    "our_y = jax.vmap(jax_quantizer.rvq_first.input_proj)(our_x)\n",
    "their_y = model.quantizer.rvq_first.input_proj(their_x)\n",
    "\n",
    "print(our_y[0, :10])\n",
    "print(their_y[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechtok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
