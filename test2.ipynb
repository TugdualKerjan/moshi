{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugdual/miniconda3/envs/mixtts/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rvq_first.input_proj.weight', 'rvq_first.output_proj.weight', 'rvq_rest.input_proj.weight', 'rvq_rest.output_proj.weight'])\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import torch\n",
    "import numpy\n",
    "from huggingface_hub import hf_hub_download\n",
    "import jax\n",
    "\n",
    "from moshi.moshi.models.loaders import get_mimi\n",
    "from moshi_jax.moshi_jax.quantization.vq import (\n",
    "    SplitResidualVectorQuantizer as JAXQuantizer,\n",
    ")\n",
    "\n",
    "_seanet_kwargs = {\n",
    "    \"channels\": 1,\n",
    "    \"dimension\": 512,\n",
    "    \"causal\": True,\n",
    "    \"n_filters\": 64,\n",
    "    \"n_residual_layers\": 1,\n",
    "    \"activation\": \"ELU\",\n",
    "    \"compress\": 2,\n",
    "    \"dilation_base\": 2,\n",
    "    \"disable_norm_outer_blocks\": 0,\n",
    "    \"kernel_size\": 7,\n",
    "    \"residual_kernel_size\": 3,\n",
    "    \"last_kernel_size\": 3,\n",
    "    # We train using weight_norm but then the weights are pre-processed for inference so\n",
    "    # that we can use a normal convolution.\n",
    "    \"norm\": \"none\",\n",
    "    \"pad_mode\": \"constant\",\n",
    "    \"ratios\": [8, 6, 5, 4],\n",
    "    \"true_skip\": True,\n",
    "}\n",
    "_quantizer_kwargs = {\n",
    "    \"dimension\": 256,\n",
    "    \"n_q\": 32,\n",
    "    \"bins\": 2048,\n",
    "    \"input_dimension\": _seanet_kwargs[\"dimension\"],\n",
    "    \"output_dimension\": _seanet_kwargs[\"dimension\"],\n",
    "}\n",
    "\n",
    "device = torch.get_default_device()\n",
    "mimi_weight = hf_hub_download(\n",
    "    \"kyutai/moshiko-pytorch-bf16\", \"tokenizer-e351c8d8-checkpoint125.safetensors\"\n",
    ")\n",
    "model = get_mimi(mimi_weight)\n",
    "\n",
    "their_params = {\n",
    "    key: jax.numpy.array(numpy.array(value.detach()))\n",
    "    for key, value in model.quantizer.named_parameters()\n",
    "}\n",
    "print(their_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_quantizer = JAXQuantizer(**_quantizer_kwargs, key=jax.random.key(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.quantizer.n_q\n",
    "jax_quantizer.n_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([433, 128, 392,   3, 300, 476, 283, 402, 300,  88], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_x = jax.random.normal(jax.random.key(1), shape=(10, 128))\n",
    "jax_quantizer.vq.layers[0]._codebook._quantize(our_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rvq_first.input_proj.weight\n",
      "rvq_first.output_proj.weight\n",
      "rvq_first.vq.layers[0]._codebook.embedding\n",
      "rvq_rest.input_proj.weight\n",
      "rvq_rest.output_proj.weight\n",
      "rvq_rest.vq.layers[0]._codebook.embedding\n",
      "T after input_proj: torch.Size([1, 256, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T after input_proj: torch.Size([1, 256, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "T during resquant: torch.Size([1, 256, 10])\n",
      "T shape pre input: torch.Size([1, 10, 256])\n",
      "T shape pre out: torch.Size([10])\n",
      "T shape post out: torch.Size([1, 10])\n",
      "QuantizedResult(x=tensor([[[-9.9130e-01, -2.2863e-01,  4.3639e+00,  ...,  2.3155e+00,\n",
      "           6.7635e-01, -1.4244e+00],\n",
      "         [-8.6464e-01,  4.1772e+00, -6.1185e+00,  ...,  8.9370e-03,\n",
      "          -3.1000e-01, -1.9839e-01],\n",
      "         [-4.3718e+00, -2.0721e+00,  5.0674e+00,  ...,  4.6619e+00,\n",
      "          -5.2325e+00,  2.8459e+00],\n",
      "         ...,\n",
      "         [ 2.6599e-01,  7.7165e+00, -7.1983e-01,  ..., -5.5553e-01,\n",
      "           1.0510e-01, -8.5815e-01],\n",
      "         [ 6.2324e+00, -7.9745e-01, -3.3376e+00,  ...,  1.6640e+00,\n",
      "          -6.9443e-01, -5.4318e+00],\n",
      "         [-2.2207e+01, -1.6745e+00,  3.3729e-01,  ...,  7.8360e+00,\n",
      "          -1.0826e+01,  2.0724e+00]]], grad_fn=<AddBackward0>), codes=tensor([[[1639,  616,  897,  468,  212, 1700, 1453, 1858, 1517,  527],\n",
      "         [1367,    9, 1270,   49,  509,  649,  655, 1358,  113, 1866],\n",
      "         [  18, 1151, 1271,  377,  532, 1255,  364,  638,  174,  873],\n",
      "         [ 187, 1066,   88,  805, 1438, 1306,  415,  329, 1111, 1900],\n",
      "         [ 853,  593, 1377,  850,  934,  193, 1297,  699, 1789, 1608],\n",
      "         [1864,  316, 1079,  505, 1471, 1365, 1280, 1580, 1553, 1874],\n",
      "         [1995,  361, 2004, 1572, 1258, 1215, 1108, 1841, 1995,  319],\n",
      "         [ 117, 1392, 1894, 1152,  801, 1617,  174,  433,  371,  780]]]), bandwidth=tensor(0.8800), penalty=tensor(0.), metrics={})\n",
      "(Array([[[-7.2774804e-01,  2.6975751e-01,  1.6391310e-01, ...,\n",
      "          1.5324568e+00, -1.3389199e+00, -9.8122811e-01],\n",
      "        [-8.7484077e-02, -9.8279845e-03,  1.2229114e+00, ...,\n",
      "         -3.0879045e-01, -1.1467636e+00, -9.2531383e-02],\n",
      "        [-6.6603434e-01, -9.7613990e-02,  2.0868988e+00, ...,\n",
      "          6.2939221e-01, -1.4252515e+00,  5.6618774e-01],\n",
      "        ...,\n",
      "        [ 1.1167738e+00,  5.3741169e+00,  4.5254469e-01, ...,\n",
      "          3.8115859e-01,  8.2831502e-02, -2.8058002e+00],\n",
      "        [ 3.3035374e+00, -2.6518598e+00, -1.8510866e+00, ...,\n",
      "         -2.8014927e+00, -1.5534852e+00, -5.1557975e+00],\n",
      "        [-1.2607681e+01, -1.3910472e+00,  4.3368149e-01, ...,\n",
      "          3.1616828e+00, -7.2866573e+00, -1.8292668e+00]]], dtype=float32), Array([[[1639,  616,  897,  468,  212, 1700, 1453, 1858, 1517,  527,\n",
      "         1367,    9, 1270,   49,  509,  649,  655, 1358,  113, 1866]]],      dtype=int32), Array([0.18], dtype=float32, weak_type=True), {})\n"
     ]
    }
   ],
   "source": [
    "import jax.tree_util as jtu\n",
    "import jax.numpy as jnp\n",
    "import numpy\n",
    "\n",
    "\n",
    "def copy_weights(path, x):\n",
    "    path = jtu.keystr(path)[1:]\n",
    "    # if \"[0].weight\"\n",
    "    if path in their_params.keys():\n",
    "        print(path)\n",
    "        return their_params[path]\n",
    "    if path == \"rvq_rest.vq.layers[0]._codebook.embedding\":\n",
    "        print(path)\n",
    "        return jnp.array(\n",
    "            numpy.array(model.quantizer.rvq_rest.vq.layers[0]._codebook.embedding)\n",
    "        )\n",
    "    if path == \"rvq_first.vq.layers[0]._codebook.embedding\":\n",
    "        print(path)\n",
    "        return jnp.array(\n",
    "            numpy.array(model.quantizer.rvq_first.vq.layers[0]._codebook.embedding)\n",
    "        )\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "jax_quantizer = jtu.tree_map_with_path(copy_weights, jax_quantizer)\n",
    "\n",
    "\n",
    "our_x = jax.random.normal(jax.random.key(1), shape=(1, 512, 10))\n",
    "their_x = torch.from_numpy(numpy.array(our_x))\n",
    "\n",
    "their_result = model.quantizer(their_x, 10)\n",
    "result = jax.vmap(jax_quantizer, in_axes=(0, None))(our_x, 10)\n",
    "\n",
    "print(their_result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
